{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7688608-72b8-43fc-a188-103a761c20d5",
   "metadata": {},
   "source": [
    "# Catapult codesign\n",
    "\n",
    "Model: `(13,21,2), n_filters=5, pool_size=3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ac2ea-c38d-417f-8b97-50757b7047b3",
   "metadata": {},
   "source": [
    "Disable some console warnings on the ASIC-group servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3d1f8c-d075-4784-9d25-7850dc9b138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_enable_xla_devices\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c2a0054-f404-4b47-b14f-263808e49c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "import json\n",
    "# from tensorflow.keras.models import Model\n",
    "from models import CreateModel\n",
    "\n",
    "from loss import *\n",
    "from qkeras import quantized_bits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d69b3-4061-4670-aabd-d17d9078316a",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc491d5-2eb1-4715-8d60-9bc17dc119d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use config info from file: /home/giuseppe/research/projects/smartpixels/data/dataset_2s, /home/giuseppe/research/projects/smartpixels/davidgjiang-smart-pixels-ml/tfrecords, /home/giuseppe/research/projects/smartpixels/davidgjiang-smart-pixels-ml/weights\n"
     ]
    }
   ],
   "source": [
    "# You can define a JSON configuration file locally\n",
    "# {\n",
    "#    \"data_base_dir\": \"/data/dajiang/smartPixels\",\n",
    "#    \"tfrecords_base_dir\" : \"/data/dajiang/smartPixels\",\n",
    "#    \"model_base_dir\": \"/home/dajiang/smart-pixels-ml/weights\"\n",
    "# }\n",
    "config_file_path = \"config.json\"\n",
    "\n",
    "# If the file does not exist, the notebook uses default values for those entries\n",
    "data_base_dir = \"/data/dajiang/smartPixels/dataset_2s\"\n",
    "tfrecords_base_dir = \"/data/dajiang/smartPixels/tfrecords\"\n",
    "model_base_dir = \"/home/dajiang/smart-pixels-ml/weights\"\n",
    "\n",
    "if os.path.exists(config_file_path):\n",
    "    with open(config_file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        data_base_dir = data.get(\"data_base_dir\")\n",
    "        tfrecords_base_dir = data.get(\"tfrecords_base_dir\")\n",
    "        model_base_dir = data.get(\"model_base_dir\")\n",
    "    print(f\"Use config info from file: {data_base_dir}, {tfrecords_base_dir}, {model_base_dir}\")\n",
    "else:\n",
    "    print(f\"File does not exist. Use default config info: {data_base_dir}, {tfrecords_base_dir}, {model_base_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea983a5-6483-4ad9-a396-36dcbdd66e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HDF5_WEIGHTS_FILE = f\"3Dallparamstiny-fastml-avgqbits-noint-4bits-8bitavg-2279bbff-checkpoints/weights.899-t-23196.44-v-25047.58.hdf5\"\n",
    "best_model_weights_hdf5 = f\"{model_base_dir}/weights_7pitches/best_model_weights.hdf5\"\n",
    "best_model_architecture_json = f\"{model_base_dir}/weights_7pitches/best_model_architecture.json\"\n",
    "best_model_hdf5 = f\"{model_base_dir}/weights_7pitches/best_model.hdf5\"\n",
    "\n",
    "# TODO: Set the right precision\n",
    "FXD_W = 4 # Fixed-point precision, word bit width\n",
    "FXD_I = 1 # Fixed-point precision, integer-part bit width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e37667-3b1e-40e1-b118-7e2505cd799e",
   "metadata": {},
   "source": [
    "## Load input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ff78ef-3220-448d-bbc7-768f47e44d28",
   "metadata": {},
   "source": [
    "### Toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c406bd-f9b2-4db5-b144-f090197da7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get rid of the toy data, and use actual data\n",
    "\n",
    "# Set a seed to have the same input traces on every run\n",
    "np.random.seed(42)\n",
    "\n",
    "B = 1\n",
    "H = 13\n",
    "W = 21\n",
    "C = 2\n",
    "\n",
    "toy_data = np.random.rand(B,\n",
    "                          H,\n",
    "                          W,\n",
    "                          C)\n",
    "\n",
    "def data_generator(left, right, step):\n",
    "    next_value = left\n",
    "    \n",
    "    def function():\n",
    "        nonlocal next_value \n",
    "        current_value = next_value\n",
    "        next_value = next_value + 0.125\n",
    "        if next_value > right:\n",
    "            next_value = -1\n",
    "        return current_value\n",
    "        \n",
    "    return function\n",
    "\n",
    "# Generate data between [-1, 0.875] step 0.125\n",
    "get_next_value = data_generator(-1, 0.875, 0.125)\n",
    "for i in range(B):\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            for d in range(C):\n",
    "                toy_data[i][h][w][d] = get_next_value()\n",
    "\n",
    "#print(toy_data.shape)\n",
    "#print(toy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb0c8a1-ec0b-4cac-99b7-3f841734f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize input data\n",
    "q_toy_data = quantized_bits(FXD_W, FXD_I-1, alpha=1)(toy_data).numpy()\n",
    "\n",
    "#print(q_toy_data.shape)\n",
    "#print(q_toy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d607bf-c391-48f2-ac8a-d857c88ea1c9",
   "metadata": {},
   "source": [
    "### Real data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46adc54f-9e15-4fbf-a80b-bdc91376ce6d",
   "metadata": {},
   "source": [
    "# TODO: Ask David to write a function to properly extract data from the tfrecord data\n",
    "\n",
    "\n",
    "def display_tfrecord_contents(tfrecord_path):\n",
    "    \"\"\"\n",
    "    Loads and displays contents of a TFRecord file.\n",
    "\n",
    "    Args:\n",
    "    - tfrecord_path: str, path to the .tfrecord file to be loaded and displayed.\n",
    "\n",
    "    Prints the contents of each record.\n",
    "    \"\"\"\n",
    "\n",
    "    def parse_tfrecord_fn(example):\n",
    "        # Define the feature description\n",
    "        feature_description = {\n",
    "            'X': tf.io.FixedLenFeature([13, 21, 2], tf.float32),  # Adjust shape if needed\n",
    "            'y': tf.io.FixedLenFeature([14, ], tf.float32),\n",
    "        }\n",
    "        example = tf.io.parse_single_example(example, feature_description)\n",
    "        \n",
    "        # Extract X directly as a float tensor\n",
    "        X = example['X']\n",
    "        y = example['y']\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    # Load and parse the TFRecord file\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    #parsed_dataset = raw_dataset.map(parse_tfrecord_fn)\n",
    "    for idx, raw_record in enumerate(raw_dataset):\n",
    "        print(f\"Record {idx + 1}:\")\n",
    "        print(len(raw_record.numpy()))  # Print the serialized raw content\n",
    "        print(\"-\" * 30)  # Separator for readability\n",
    "    # Display the content of each record\n",
    "    # for idx, (X, y) in enumerate(parsed_dataset):\n",
    "    #     print(f\"Record {idx + 1}:\")\n",
    "    #     print(\"X shape:\", X.shape)\n",
    "    #     print(\"X content:\\n\", X.numpy())\n",
    "    #     print(\"y shape:\", y.shape)\n",
    "    #     print(\"y content:\\n\", y.numpy())\n",
    "    #     print(\"-\" * 30)  # Separator for readability\n",
    "\n",
    "\n",
    "display_tfrecord_contents(\"tfrecords/tfrecords_20t_val_50x12P5_bnorm_timeslices2/batch_0.tfrecord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba246f-3201-4577-b406-917a210853a9",
   "metadata": {},
   "source": [
    "## QKeras model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c0956-4409-4b9b-aed1-e959090fbf01",
   "metadata": {},
   "source": [
    "### Load QKeras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3069d57-0482-4352-8050-290d0c17a9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13, 21, 2)]       0         \n",
      "                                                                 \n",
      " q_separable_conv2d (QSepar  (None, 11, 19, 5)         33        \n",
      " ableConv2D)                                                     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 11, 19, 5)         20        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 11, 19, 5)         0         \n",
      "                                                                 \n",
      " q_conv2d (QConv2D)          (None, 11, 19, 5)         30        \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 11, 19, 5)         20        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_1 (QActivatio  (None, 11, 19, 5)         0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 3, 6, 5)           0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 3, 6, 5)           0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 90)                0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 16)                1456      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_3 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_1 (QDense)          (None, 16)                272       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_4 (QActivatio  (None, 16)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_dense_2 (QDense)          (None, 14)                238       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2197 (8.58 KB)\n",
      "Trainable params: 2113 (8.25 KB)\n",
      "Non-trainable params: 84 (336.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the whole model from HDF5 file\n",
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "\n",
    "co = {\"custom_loss\": custom_loss}\n",
    "_add_supported_quantized_objects(co)\n",
    "model = load_model(best_model_hdf5, custom_objects=co)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4879e-d3d3-48eb-be49-23c29472f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This gives an error:\n",
    "# ValueError: Layer count mismatch when loading weights from file. Model expected 5 layers, found 9 saved layers.\n",
    "#\n",
    "# # Load model weights from HDF5 file, while recreate architecture from scripts\n",
    "# model = CreateModel((13,21,2), n_filters=5, pool_size=3)\n",
    "# model.load_weights(best_model_weights_hdf5)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526dfa2-cb84-430f-ace0-b4da8e610e51",
   "metadata": {},
   "source": [
    "### Slice QKeras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743aa20c-b395-4eae-88ec-14e41e0a141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLICE_TO_LAYER_NUM = 12\n",
    "# print(\"Layer count: {}/{}\".format(SLICE_TO_LAYER_NUM, len(model.layers)-1))\n",
    "# assert(SLICE_TO_LAYER_NUM < len(model.layers))\n",
    "# model = Model(inputs=model.input, \n",
    "#                   outputs=model.layers[SLICE_TO_LAYER_NUM].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc89546-2203-41fa-a800-c41f6d52900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "# plot_model(model, to_file=\"model.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6886474-7b5a-4604-8880-bbba4db689b7",
   "metadata": {},
   "source": [
    "### Run QKeras model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c19f3b-4ec4-41b0-8a05-942e56fde9ef",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966e334-4d41-4f01-b0c7-71b7bc66aa2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Use real data\n",
    "\n",
    "y_qkeras = model.predict(np.ascontiguousarray(q_toy_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73abc0f0-ccb9-4d18-95ab-2289032174db",
   "metadata": {},
   "source": [
    "#### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3467ab2e-3355-4df2-82be-0ac8ffd09875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use real data\n",
    "\n",
    "qkeras_trace = hls4ml.model.profiling.get_ymodel_keras(model, q_toy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13514e92",
   "metadata": {},
   "source": [
    "#### Save .dat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ec5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use real data\n",
    "\n",
    "# Save input features and model predictions just the top 20\n",
    "np.savetxt(\"tb_input_features.dat\", q_toy_data.reshape(B, -1), fmt=\"%f\")\n",
    "np.savetxt(\"tb_output_predictions.dat\", y_qkeras, fmt=\"%f\")\n",
    "#np.savetxt(\"y_test_labels.dat\", y_test, fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba40be0-aa45-4e6f-a384-a56fce823ccf",
   "metadata": {},
   "source": [
    "## hls4ml model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f3595-8462-4799-b8fb-cb97a8e15566",
   "metadata": {},
   "source": [
    "### Configure hls4ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04679e0-4bef-47a7-9df2-29fe124a9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ccs = hls4ml.utils.config.create_config(\n",
    "    backend = \"Catapult\",\n",
    "    project_name = \"myproject\",\n",
    "    output_dir = \"myproject_hls4ml_prj\",\n",
    "    tech = \"asic\",\n",
    "    asiclibs = \"saed32rvt_tt0p78v125c_beh\",\n",
    "    asicfifo = \"hls4ml_lib.mgc_pipe_mem\",\n",
    "    clock_period = 10,\n",
    "    io_type = \"io_parallel\",\n",
    "    csim=0, SCVerify=0, Synth=1\n",
    ")\n",
    "#print(config_ccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a619c30-6145-4352-805f-41ed07bb67b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ccs[\"HLSConfig\"] = hls4ml.utils.config_from_keras_model(\n",
    "    model,\n",
    "    granularity=\"name\",\n",
    "    default_precision=\"ac_fixed<16,6,true>\",\n",
    "    default_reuse_factor=1\n",
    ")\n",
    "\n",
    "# Point to the model definition, weights/biase values and C++ testbench data files\n",
    "config_ccs[\"KerasH5\"] = best_model_weights_hdf5\n",
    "config_ccs[\"KerasJson\"] = best_model_architecture_json\n",
    "config_ccs[\"InputData\"] = \"tb_input_features.dat\"\n",
    "config_ccs[\"OutputPredictions\"] = \"tb_output_predictions.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a81200e-f8b8-4eef-aa88-57d01dd6dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: is this necessary?\n",
    "\n",
    "with open(\"myproject_config.yml\", \"w\") as yaml_file:\n",
    "    yaml.dump(config_ccs, yaml_file, explicit_start=False, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc01af-6ba3-4bd9-8706-e11a2e042fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable tracing for all of the layers\n",
    "for layer in config_ccs[\"HLSConfig\"][\"LayerName\"].keys():\n",
    "    print(\"Enable tracing for layer:\", layer)\n",
    "    config_ccs[\"HLSConfig\"][\"LayerName\"][layer][\"Trace\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed56d487-7dc4-4742-8808-c6f0a4cb3f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert QKeras model to Catapult HLS C++\n",
    "hls_model_ccs = hls4ml.converters.keras_to_hls(config_ccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c60a0b-dfaa-427a-8791-e8d56a526cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hls4ml.utils.plot_model(hls_model_ccs, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4767a7-e114-4ae2-91a0-ae1c3c82a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing HLS project\n",
    "hls_model_ccs.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c8015f-94b9-4cab-9c61-1b33a30b30b7",
   "metadata": {},
   "source": [
    "### Run hls4ml model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb606c-62de-42a6-aced-ba7eef729253",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb6031-54a2-49b9-89d6-dde566a41ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use real data\n",
    "\n",
    "y_ccs = hls_model_ccs.predict(np.ascontiguousarray(q_toy_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9148f445-b977-4b16-b590-aadef11f6d9e",
   "metadata": {},
   "source": [
    "#### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ce844-8477-4020-8c97-77688489a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use real data\n",
    "\n",
    "# Run tracing on the test set for the hls4ml model (fixed-point precision) \n",
    "pred_ccs, trace_ccs = hls_model_ccs.trace(q_toy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f678c0-6a6d-468f-b988-3f25c8bea203",
   "metadata": {},
   "source": [
    "## Compare QKeras and hls4ml"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5053bb1f-4267-4da4-ba18-7492f1d71b91",
   "metadata": {},
   "source": [
    "print(y_qkeras[0].flatten())\n",
    "print(y_ccs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f2a311-03f4-40db-9749-ad1992289a83",
   "metadata": {},
   "source": [
    "#### Trace visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5945f5b-3a82-4193-a1b6-4bcbd77e524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the traces on console\n",
    "N_ELEMENTS=10\n",
    "\n",
    "# Backup print options\n",
    "bkp_threshold = np.get_printoptions()[\"threshold\"]\n",
    "bkp_linewidth = np.get_printoptions()[\"linewidth\"]\n",
    "\n",
    "# Set print options\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "print(\"input\", toy_data[0][0][0][:N_ELEMENTS])\n",
    "for key in trace_ccs.keys():\n",
    "    print(\"-------\")\n",
    "    print(key, trace_ccs[key].shape)\n",
    "    print(\"[keras] \", key, qkeras_trace[key].flatten()[:N_ELEMENTS])\n",
    "    #print(mse(hls4ml_trace[key][0].flatten(), qkeras_trace[key][0].flatten()))\n",
    "    print(\"[hls4ml]\", key, trace_ccs[key].flatten()[:N_ELEMENTS])\n",
    "    #print(key, qkeras_trace[key].shape)\n",
    "    \n",
    "# Restore print options\n",
    "np.set_printoptions(threshold=bkp_threshold, linewidth=bkp_linewidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e268e2-ed27-4861-bbed-863cfd82855c",
   "metadata": {},
   "source": [
    "#### MSE per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d217387-b8ef-4bf0-998b-cbf5e1ca3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(actual, predicted):\n",
    "    return ((actual - predicted) ** 2).mean()\n",
    "\n",
    "for key in trace_ccs.keys():\n",
    "    print(\"-------\")\n",
    "    print(\"MSE {} {}\".format(key, mse(trace_ccs[key][0].flatten(), qkeras_trace[key].flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91eee55-21e0-45fc-b6f9-f704bb52943f",
   "metadata": {},
   "source": [
    "#### Correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cebdd68-ef0a-4b22-82b5-623082831e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Evaluate correlation plots\n",
    "for layer in trace_ccs.keys():\n",
    "    if \"_alpha\" in layer:\n",
    "        continue\n",
    "    plt.figure()\n",
    "    klayer = layer\n",
    "    if \"_linear\" in layer:\n",
    "        klayer = layer.replace(\"_linear\", \"\")\n",
    "    min_x = min(np.amin(trace_ccs[layer]), np.amin(qkeras_trace[klayer]))\n",
    "    max_x = max(np.amax(trace_ccs[layer]), np.amax(qkeras_trace[klayer]))\n",
    "    golden_min_x = np.amin(qkeras_trace[klayer])\n",
    "    golden_max_x = np.amax(qkeras_trace[klayer])\n",
    "    #print(\"{}, range [{}, {}], range {}, bits {}\".format(layer, golden_min_x, golden_max_x, abs(golden_min_x) + abs(golden_max_x), math.ceil(math.log2(abs(golden_min_x) + abs(golden_max_x)))))\n",
    "    plt.plot([min_x, max_x], [min_x, max_x], c=\"gray\")\n",
    "    plt.scatter(trace_ccs[layer].flatten(), qkeras_trace[klayer].flatten(), s=0.2, c=\"red\")\n",
    "    plt.xlabel(\"hls4ml {}\".format(layer))\n",
    "    plt.ylabel(\"QKeras {}\".format(klayer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f419d4-fa82-46da-80f5-2e8ab882618c",
   "metadata": {},
   "source": [
    "## Model synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8272b-4701-42af-8499-eab8fcdf6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# TODO: Check the parameters for the build function (Catapult)\n",
    "\n",
    "#report = hls_model.build(csim=True, synth=False, cosim=False, validation=False, export=False, vsynth=False, reset=False)\n",
    "report = hls_model_ccs.build(csim=True, synth=True, cosim=False, validation=False, export=False, vsynth=False, bup=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf7400-0d17-45e7-b8fe-09e34cbcbcb6",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52cfbec4-4c04-46ec-a251-5ccf97a124dd",
   "metadata": {},
   "source": [
    "import subprocess\n",
    "\n",
    "def run_command(cmd):\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, shell=True)\n",
    "    return result.stdout, result.stderr\n",
    "\n",
    "def print_report(report, fpga_part = \"?\", vivado_version = \"?\", knobs = {}, hls = True, syn = True, cosim = True):\n",
    "    hls_results = report[\"CSynthesisReport\"]\n",
    "    syn_results = report[\"VivadoSynthReport\"]\n",
    "    cosim_results = report[\"CosimReport\"]\n",
    "    if hls:\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"Vivado version: {}\".format(vivado_version))\n",
    "        print(\"FPGA part:      {}\".format(fpga_part))\n",
    "        print(\"Knobs:          {}\".format(knobs))\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"HLS\")\n",
    "        print(\"Target Clock Period:    {} ns\".format(hls_results[\"TargetClockPeriod\"]))\n",
    "        print(\"Estimated Clock Period: {} ns\".format(hls_results[\"EstimatedClockPeriod\"]))\n",
    "        print(\"Best/Worst Latency: {} / {}\".format(hls_results[\"BestLatency\"], hls_results[\"WorstLatency\"]))\n",
    "        print(\"Interval Min/Max:   {} / {}\".format(hls_results[\"IntervalMin\"], hls_results[\"IntervalMax\"]))\n",
    "        print(\"BRAM_18K:           {}, {:0.1f}% (Aval. {})\".format(hls_results[\"BRAM_18K\"], float(hls_results[\"BRAM_18K\"])*100.0/int(hls_results[\"AvailableBRAM_18K\"]), hls_results[\"AvailableBRAM_18K\"]))\n",
    "        print(\"DSP:                {}, {:0.1f}% (Aval. {})\".format(hls_results[\"DSP\"], float(hls_results[\"DSP\"])*100.0/int(hls_results[\"AvailableDSP\"]), hls_results[\"AvailableDSP\"]))\n",
    "        print(\"FF:                 {}, {:0.1f}% (Aval. {})\".format(hls_results[\"FF\"], float(hls_results[\"FF\"])*100.0/int(hls_results[\"AvailableFF\"]), hls_results[\"AvailableFF\"]))\n",
    "        print(\"LUT:                {}, {:0.1f}% (Aval. {})\".format(hls_results[\"LUT\"], float(hls_results[\"LUT\"])*100.0/int(hls_results[\"AvailableLUT\"]), hls_results[\"AvailableLUT\"]))\n",
    "        #print(\"URAM:                   {}, {} (Aval. {})\".format(hls_results[\"URAM\"], int(hls_results[\"URAM\"])*100.0/int(hls_results[\"AvailableURAM\"]), hls_results[\"AvailableURAM\"]))\n",
    "    if syn:\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"Synthesis\")\n",
    "        print(\"BRAM_18K:           {}, {:0.1f}% (Aval. {})\".format(syn_results[\"BRAM_18K\"], float(syn_results[\"BRAM_18K\"])*100.0/int(hls_results[\"AvailableBRAM_18K\"]), hls_results[\"AvailableBRAM_18K\"]))\n",
    "        print(\"DSP:                {}, {:0.1f}% (Aval. {})\".format(syn_results[\"DSP48E\"], float(syn_results[\"DSP48E\"])*100.0/int(hls_results[\"AvailableDSP\"]), hls_results[\"AvailableDSP\"]))\n",
    "        print(\"FF:                 {}, {:0.1f}% (Aval. {})\".format(syn_results[\"FF\"], float(syn_results[\"FF\"])*100.0/int(hls_results[\"AvailableFF\"]), hls_results[\"AvailableFF\"]))\n",
    "        print(\"LUT:                {}, {:0.1f}% (Aval. {})\".format(syn_results[\"LUT\"], float(syn_results[\"LUT\"])*100.0/int(hls_results[\"AvailableLUT\"]), hls_results[\"AvailableLUT\"]))\n",
    "    if syn:\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"Cosimulation\")\n",
    "        print(\"Max/Min Latency:    {} / {}\".format(cosim_results[\"LatencyMax\"], cosim_results[\"LatencyMin\"]))\n",
    "        print(\"Avg Latency:        {}\".format(cosim_results[\"LatencyAvg\"]))\n",
    "        print(\"Max/Min Interval:   {} / {}\".format(cosim_results[\"IntervalMax\"], cosim_results[\"IntervalMin\"]))\n",
    "        print(\"Avg Interval:       {}\".format(cosim_results[\"IntervalAvg\"]))\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ce63271-ecdc-4145-9613-129a1f65d467",
   "metadata": {},
   "source": [
    "print_report(report,\n",
    "    fpga_part=\"xcu250-figd2104-2L-e\",\n",
    "    vivado_version=vivado_version,\n",
    "    knobs = {\"backend\" : BACKEND, \"io_type\" : IO_TYPE, \"strategy\" : STRATEGY}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
